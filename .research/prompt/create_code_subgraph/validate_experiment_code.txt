
LLM Name: o3-2025-04-16
Input:
You are an AI code reviewer validating production-ready experiment code for research papers.

Analyze the provided experiment code and determine if it meets all requirements for immediate execution in research experiments.

# Instructions

## Core Validation Criteria
Check if the generated experiment code meets ALL of the following requirements:

1. **Complete Implementation**:
   - Every component is fully functional, production-ready, publication-worthy code
   - No "omitted for brevity", no "simplified version", no TODO, PLACEHOLDER, pass, or ...
   - All functions and classes are completely implemented
   - No truncated code sections or incomplete implementations

2. **Hydra Integration**:
   - Uses Hydra to manage all experiment configurations from `config/run/*.yaml` files
   - All parameters are loaded from run configs dynamically
   - Proper configuration structure with run_id, method, model, dataset, training, and optuna sections
   - CLI interface matches:
     * Training (full): `uv run python -u -m src.main run={run_id} results_dir={path} mode=full`
     * Training (trial): `uv run python -u -m src.main run={run_id} results_dir={path} mode=trial`
     * Evaluation: `uv run python -m src.evaluate results_dir={path} run_ids='["run-1", "run-2", ...]'` (independent execution)
   - Code must automatically configure based on mode:
     * When `cfg.mode == "trial"`: Set `cfg.wandb.mode = "disabled"`, `cfg.optuna.n_trials = 0`, epochs=1
     * When `cfg.mode == "full"`: Set `cfg.wandb.mode = "online"` and use full configuration

3. **Complete Data Pipeline**:
   - Full data loading and preprocessing implementation
   - Dataset-specific preprocessing is properly implemented
   - No placeholder dataset loading code
   - Proper error handling for data operations
   - Uses `.cache/` as the cache directory for all datasets and models

4. **Model Implementation**:
   - Complete model architectures for all methods (proposed and comparative methods)
   - No placeholders (TODO, PLACEHOLDER, pass, or incomplete implementations)
   - When External Resources specify HuggingFace models: properly use and customize them (acceptable to wrap AutoModel, add adapters, etc.)
   - When no external models specified: implement architectures from scratch using PyTorch primitives
   - Model-specific configurations correctly applied
   - Proper PyTorch usage throughout

5. **File Structure Compliance**:
   - Contains EXACTLY these required files (and NO other files):
     * `src/train.py`
     * `src/evaluate.py`
     * `src/preprocess.py`
     * `src/model.py`
     * `src/main.py`
     * `pyproject.toml`
     * `config/config.yaml`
   - NO additional files (e.g., NO `src/__init__.py`, NO `setup.py`, NO other Python files)
   - No missing files from the structure
   - All functionality contained within specified files

6. **WandB Integration**:
   - train.py initializes WandB and logs ALL metrics comprehensively:
     * Use `wandb.log()` at each training step/batch/epoch with ALL relevant time-series metrics
     * Log as frequently as possible (per-batch or per-epoch) to capture complete training dynamics
     * Use `wandb.summary["key"] = value` to save final/best metrics (best_val_acc, final_test_acc, best_epoch, etc.)
     * Metric names in train.py's wandb.log() MUST exactly match the keys used in evaluate.py's run.history()
   - Optuna Integration: If using Optuna, DO NOT log intermediate trial results to WandB - only log the final run with best hyperparameters
   - Code must automatically configure based on mode:
     * When `cfg.mode == "trial"`: Set `cfg.wandb.mode = "disabled"` before any WandB operations
     * When `cfg.mode == "full"`: Set `cfg.wandb.mode = "online"` before any WandB operations
   - NO results.json or stdout JSON dumps in train.py
   - config/config.yaml contains mandatory WandB settings (entity/project)
   - `WANDB_API_KEY` environment variable is available for authentication

7. **Configuration Files**:
   - The generated code properly references config files via Hydra
   - NOTE: config/run/{run_id}.yaml files are provided separately (not in ExperimentCode)
   - All run configurations match the experiment_runs provided
   - Optuna search spaces are properly defined if applicable

8. **Evaluation Script Independence**:
   - evaluate.py is executed independently via `uv run python -m src.evaluate results_dir={path} run_ids='["run-1", "run-2"]'`
   - Accepts `run_ids` parameter as JSON string list (parse with `json.loads(args.run_ids)`)
   - main.py DOES NOT call evaluate.py
   - evaluate.py loads WandB config from `config/config.yaml` (in repository root)
   - evaluate.py retrieves comprehensive data from WandB API:
     * Use `wandb.Api()` to get run data: `run = api.run(f"{entity}/{project}/{run_id}")`
     * Retrieve: `history = run.history()`, `summary = run.summary._json_dict`, `config = dict(run.config)`
   - **STEP 1: Per-Run Processing** (for each run_id):
     * Export comprehensive run-specific metrics to: `{results_dir}/{run_id}/metrics.json`
     * Generate run-specific figures (learning curves, confusion matrices) to: `{results_dir}/{run_id}/`
     * Each run should have its own subdirectory with its metrics and figures
   - **STEP 2: Aggregated Analysis** (after processing all runs):
     * Export aggregated metrics to: `{results_dir}/comparison/aggregated_metrics.json`
     * Compute secondary/derived metrics (e.g., improvement rate: (proposed - baseline) / baseline)
     * Generate comparison figures to: `{results_dir}/comparison/`
     * Cross-run comparison charts (bar charts, box plots)
     * Performance metrics tables
     * Statistical significance tests
   - Proper figure quality: legends, annotations, tight_layout
   - Follows GLOBALLY UNIQUE naming convention to prevent collisions:
     * Per-run figures: `{run_id}_{figure_topic}[_<condition>][_pairN].pdf` (e.g., `run-1-proposed-bert-glue_learning_curve.pdf`)
     * Comparison figures: `comparison_{figure_topic}[_<condition>][_pairN].pdf` (e.g., `comparison_accuracy_bar_chart.pdf`)
   - train.py and main.py generate NO figures
   - evaluate.py cannot run in trial_mode (no WandB data available when WandB disabled)

9. **Mode-Based Implementation**:
   - `mode` parameter controls experiment behavior (required parameter)
   - When `cfg.mode == "trial"`:
     * Properly reduces computational load: epochs=1, batches limited to 1-2, Optuna disabled (n_trials=0), small evaluation subset
     * Automatically sets `cfg.wandb.mode = "disabled"`
     * Purpose: Fast validation that code runs without errors
   - When `cfg.mode == "full"`:
     * Automatically sets `cfg.wandb.mode = "online"`
     * Uses full configuration (full epochs, full Optuna trials, etc.)

## Output Format
Respond with a JSON object containing:
- `is_code_ready`: boolean - true if ALL criteria are met, false otherwise
- `code_issue`: string - specific issues found if any criteria are not met, focusing on what needs to be fixed

# Hypothesis
open_problems='AdaLoRA shows that allocating the same LoRA rank to every weight matrix is sub-optimal, but its SVD-based importance metric (sensitivity + uncertainty on every singular triplet) costs an extra 11-16 % training time and requires additional code that is hard to port. Can we obtain most of the accuracy gain of adaptive rank allocation with a much cheaper signal that is already produced during standard back-propagation?' method='Gradient-Norm Aware Rank Allocation for LoRA (GLoRA)\n1. Keep the ordinary LoRA parameterisation W  ←  W  +  Δ where Δ=AB^T,  rank r.\n2. During the first Twarmup optimisation steps record, for every trainable weight matrix k, the exponential-moving-average (EMA) of its LoRA gradient Frobenius norm:  g_k  ←  β·g_k  +  (1-β)·||∂L/∂Δ_k||_F.\n3. After warm-up compute importance scores  s_k  =  g_k / Σ_j g_j.\n4. Given a global rank budget Rtotal (e.g. 128), assign matrix-specific ranks  r_k  =  round( Rtotal · s_k ).  Ensure Σ_k r_k  =  Rtotal by adding / removing 1 where needed.\n5. Re-initialise each LoRA layer with its new rank (easy because LoRA stores A∈ℝ^{d×r}, B∈ℝ^{d×r}).  The already learned sub-matrices for the kept columns are copied; extra columns are created with the same init as LoRA; dropped columns are discarded.  Training then continues normally.\n\nWhy it should work: the gradient norm is a first-order estimate of how much the loss would change if the associated parameters were perturbed. It therefore correlates with parameter importance but is essentially free to compute (it is produced anyway by back-prop).  Unlike AdaLoRA we do not need an SVD or per-singular-value statistics, so no extra forward / backward passes are introduced.' experimental_setup='Model: DeBERTa-v3-base (same as AdaLoRA paper).\nTasks: GLUE (MNLI, SST-2, RTE) – three representative tasks to keep the demo light.\nBaselines: (1) Ordinary LoRA with uniform rank r=8 per matrix (≈0.2 % params). (2) AdaLoRA with the same global budget (re-implemented from the official repo). (3) Proposed GLoRA with Rtotal = number of LoRA matrices × 8.\nHyper-parameters: identical to LoRA baseline (lr=2e-4, batch=32, 3 epochs).  Warm-up Twarmup = one epoch, β = 0.9.\nMetrics: task-specific dev set accuracy / Matthew’s Corr.; wall-clock training time.  Each experiment is run with a single V100 for fair timing.' experimental_code='# -------- glo_ra.py --------\nimport torch, math\nfrom peft import get_peft_model, LoraConfig   # pip install peft\n\nclass GLoRAWrapper:\n    """Wrap a HF model with gradient-norm aware rank allocation."""\n    def __init__(self, hf_model, r_init=8, total_rank=128, beta=0.9, warmup_steps=1000):\n        self.model = get_peft_model(hf_model, LoraConfig(r=r_init))\n        self.total_rank = total_rank\n        self.beta = beta\n        self.warmup_steps = warmup_steps\n        self.step = 0\n        # collect lora modules\n        self.lora_modules = [m for m in self.model.modules() if hasattr(m, "lora_A")]\n        self.g_ema = torch.zeros(len(self.lora_modules), device=hf_model.device)\n        # register hooks to capture grad norms\n        for idx, m in enumerate(self.lora_modules):\n            m.lora_B.register_hook(self._make_hook(idx))\n\n    def _make_hook(self, idx):\n        def hook(grad):\n            gn = grad.norm()  # frobenius\n            self.g_ema[idx] = self.beta * self.g_ema[idx] + (1 - self.beta) * gn\n        return hook\n\n    def step_callback(self):\n        self.step += 1\n        if self.step == self.warmup_steps:\n            # allocate new ranks\n            scores = self.g_ema / self.g_ema.sum()\n            ranks = torch.round(scores * self.total_rank).int().tolist()\n            # exact budget fix\n            diff = self.total_rank - sum(ranks)\n            for i in range(abs(diff)):\n                ranks[i % len(ranks)] += 1 if diff > 0 else -1\n            # rebuild LoRA layers\n            for new_r, mod in zip(ranks, self.lora_modules):\n                old_r = mod.lora_A.weight.size(0)\n                if new_r == old_r:  # nothing to do\n                    continue\n                # keep the first min(old_r, new_r) columns\n                keep = min(old_r, new_r)\n                with torch.no_grad():\n                    A_old, B_old = mod.lora_A.weight.data[:keep], mod.lora_B.weight.data[:keep]\n                    mod.update_layer(r=new_r)  # provided by peft, re-initialises weights\n                    mod.lora_A.weight.data[:keep] = A_old\n                    mod.lora_B.weight.data[:keep] = B_old\n            print("[GLoRA] re-allocated ranks", ranks)\n' expected_result='1. Accuracy: GLoRA ≈ AdaLoRA > vanilla LoRA.  We expect +0.5-1.0 GLUE score points over uniform LoRA, matching 90-95 % of AdaLoRA’s gain.\n2. Training time: GLoRA ≈ LoRA (within ±2 %), clearly faster than AdaLoRA (which reports +11-16 %).\n3. Parameter count: identical to AdaLoRA, both respect the same global budget.' expected_conclusion='A single extra bookkeeping line (EMA of gradient norms) is enough to reap most of the benefits of adaptive budget allocation without incurring the computational overhead of AdaLoRA’s SVD-based importance analysis.  This demonstrates that inexpensive first-order signals already available in standard training loops can guide parameter-efficient fine-tuning, making advanced PEFT techniques accessible to practitioners with limited hardware or engineering budget.'

# Current Research Method
Gradient-Norm Aware Rank Allocation for LoRA (GLoRA)
1. Keep the ordinary LoRA parameterisation W  ←  W  +  Δ where Δ=AB^T,  rank r.
2. During the first Twarmup optimisation steps record, for every trainable weight matrix k, the exponential-moving-average (EMA) of its LoRA gradient Frobenius norm:  g_k  ←  β·g_k  +  (1-β)·||∂L/∂Δ_k||_F.
3. After warm-up compute importance scores  s_k  =  g_k / Σ_j g_j.
4. Given a global rank budget Rtotal (e.g. 128), assign matrix-specific ranks  r_k  =  round( Rtotal · s_k ).  Ensure Σ_k r_k  =  Rtotal by adding / removing 1 where needed.
5. Re-initialise each LoRA layer with its new rank (easy because LoRA stores A∈ℝ^{d×r}, B∈ℝ^{d×r}).  The already learned sub-matrices for the kept columns are copied; extra columns are created with the same init as LoRA; dropped columns are discarded.  Training then continues normally.

Why it should work: the gradient norm is a first-order estimate of how much the loss would change if the associated parameters were perturbed. It therefore correlates with parameter importance but is essentially free to compute (it is produced anyway by back-prop).  Unlike AdaLoRA we do not need an SVD or per-singular-value statistics, so no extra forward / backward passes are introduced.

# Experimental Design
- Strategy: We will verify that the inexpensive gradient-norm aware rank allocation strategy for LoRA (GLoRA) can recover almost all the accuracy benefit of AdaLoRA while keeping training cost identical to vanilla LoRA.  The experiment fine-tunes the encoder-only DeBERTa-v3-base model on the MNLI portion of GLUE using three different parameter-efficient fine-tuning schemes:  (1) ordinary LoRA with a fixed rank of 8 for every projection matrix; (2) AdaLoRA, the published adaptive-rank baseline; (3) the proposed GLoRA.  All runs share the same optimisation schedule and global LoRA-rank budget.  During the first warm-up epoch GLoRA keeps a running EMA of the Frobenius norm of each LoRA gradient; the resulting scores are used to redistribute the fixed total rank across layers.  Because the signal is collected during the normal backward pass, no extra training steps or SVDs are introduced.  At the warm-up boundary the LoRA modules are rebuilt with their newly assigned ranks and training proceeds for the remaining epochs.  We measure development-set accuracy and Matthews correlation on MNLI and record wall-clock training time on one A100 to demonstrate that GLoRA matches AdaLoRA’s accuracy with LoRA-level speed.
- Proposed Method: Gradient-Norm Aware Rank Allocation for LoRA (GLoRA)
Objective: Achieve adaptive allocation of the LoRA rank budget across layers without the heavy SVD-based importance analysis used by AdaLoRA.
Algorithm:
1. Start from the standard LoRA formulation Δ=ABᵀ with an initial uniform rank r_init.
2. For every LoRA layer k maintain an exponential moving average g_k of its gradient Frobenius norm:
   g_k ← β·g_k + (1−β)·∥∂L/∂Δ_k∥_F.
3. Collect g_k during the first T_warmup optimisation steps (one epoch in our setup).
4. After warm-up compute importance scores s_k = g_k / Σ_j g_j and convert them into integer ranks r_k = round(R_total·s_k).  Correct rounding so Σ_k r_k = R_total.
5. Re-initialise each LoRA module with its new rank, copying already learned columns that are kept and randomly initialising added columns.
6. Continue training for the remaining epochs with the redistributed budget.
Implementation details:
• A lightweight wrapper around HuggingFace PEFT registers backward hooks on lora_B weights to accumulate gradient norms, adding virtually zero overhead.
• Rank re-allocation uses the update_layer() utility supplied by PEFT, so no custom CUDA kernels are required.
• Hyper-parameters identical to vanilla LoRA: AdamW, lr=2e-4, batch=32, 3 epochs.  Only β (0.9), T_warmup (1 epoch) and R_total (num_layers×8) are additional.
Theoretical motivation: The gradient norm is a first-order proxy for the loss sensitivity to parameter perturbations; allocating more capacity where this sensitivity is high should maximise loss reduction per parameter—mirroring the intuition behind AdaLoRA but without second-order analysis.
- Evaluation Metrics: ['Accuracy', 'Matthews Correlation', 'Wall-clock Training Time']

# Experiment Runs

- Run ID: proposed-DeBERTa-v3-base-86M--GLUE-MNLI
  Method: proposed
  Model: DeBERTa-v3-base (86M)
  Dataset: GLUE MNLI
  
  Config Content:
  ```yaml
  run_id: proposed-DeBERTa-v3-base-86M--GLUE-MNLI
method: proposed
method_name: GLoRA
model:
  backbone: microsoft/deberta-v3-base
  peft:
    type: lora
    init_rank: 8
  hidden_size: 768
  num_layers: 12
  num_parameters: 86M
dataset:
  name: glue_mnli
  max_length: 256
  batch_size: 32
training:
  epochs: 3
  optimizer: adamw
  learning_rate: 2e-4
  weight_decay: 0.01
  lr_scheduler: linear
  lr_warmup_steps: 1000
  max_grad_norm: 1.0
  gradient_checkpointing: false
glo_ra:
  total_rank_budget: 128
  beta_ema: 0.9
  warmup_steps: 12000
evaluation:
  metrics: [accuracy, matthews_corrcoef]
  track_training_time: true
hardware:
  gpu_type: a100
  num_gpus: 1
optuna:
  n_trials: 25
  direction: maximize
  metric: validation_accuracy
  search_space:
    learning_rate:
      type: loguniform
      low: 1.0e-4
      high: 5.0e-4
    beta_ema:
      type: uniform
      low: 0.8
      high: 0.99
    total_rank_budget:
      type: categorical
      choices: [96, 128, 160]
    warmup_steps:
      type: int
      low: 500
      high: 1500
    batch_size:
      type: categorical
      choices: [16, 32, 64]

  ```
  

- Run ID: comparative-1-DeBERTa-v3-base-86M--GLUE-MNLI
  Method: comparative-1
  Model: DeBERTa-v3-base (86M)
  Dataset: GLUE MNLI
  
  Config Content:
  ```yaml
  run_id: comparative-1-DeBERTa-v3-base-86M--GLUE-MNLI
method: comparative-1
method_name: AdaLoRA
model:
  backbone: microsoft/deberta-v3-base
  peft:
    type: adalora
    init_rank: 8
  hidden_size: 768
  num_layers: 12
  num_parameters: 86M
dataset:
  name: glue_mnli
  max_length: 256
  batch_size: 32
training:
  epochs: 3
  optimizer: adamw
  learning_rate: 2e-4
  weight_decay: 0.01
  lr_scheduler: linear
  lr_warmup_steps: 1000
  max_grad_norm: 1.0
  gradient_checkpointing: false
adalora:
  total_rank_budget: 128
  init_rank: 8
  beta1: 0.9
  beta2: 0.99
  orth_reg_weight: 5.0e-4
  adaptation_start_step: 12000
evaluation:
  metrics: [accuracy, matthews_corrcoef]
  track_training_time: true
hardware:
  gpu_type: a100
  num_gpus: 1
optuna:
  n_trials: 25
  direction: maximize
  metric: validation_accuracy
  search_space:
    learning_rate:
      type: loguniform
      low: 1.0e-4
      high: 5.0e-4
    orth_reg_weight:
      type: loguniform
      low: 1.0e-5
      high: 1.0e-3
    adaptation_start_step:
      type: int
      low: 500
      high: 1500
    total_rank_budget:
      type: categorical
      choices: [96, 128, 160]
    batch_size:
      type: categorical
      choices: [16, 32, 64]

  ```
  


# Generated Experiment Code (To be validated)
{"config_yaml": "# config/config.yaml\n# Global Hydra configuration (shared by all scripts)\n\ndefaults:\n  - _self_\n  - run: null\n\n# -----------------------------------------------------------------------------\n# WandB credentials (overridden to \u0027disabled\u0027 for trial mode) ------------------\nwandb:\n  entity: gengaru617-personal\n  project: 251106-test\n  mode: online\n\n# -----------------------------------------------------------------------------\n# Generic training defaults ----------------------------------------------------\ntraining:\n  epochs: 3\n  learning_rate: 2e-4\n  weight_decay: 0.01\n  lr_warmup_steps: 1000\n  gradient_accumulation_steps: 1\n  max_grad_norm: 1.0\n  max_train_batches: null     # limited in trial mode\n  max_val_batches: null       # NEW \u2013 limited in trial mode\n\n# -----------------------------------------------------------------------------\n# Optuna (disabled unless n_trials\u003e0) ------------------------------------------\noptuna:\n  n_trials: 0\n  direction: maximize\n  search_space: {}\n\n# -----------------------------------------------------------------------------\n# Execution control ------------------------------------------------------------\nmode: full            # full / trial\nresults_dir: ./results\n\n# End of global config ---------------------------------------------------------\n", "evaluate_py": "\"\"\"src/evaluate.py\nIndependent evaluation / visualisation script executed *after* all training\nruns.  Fetches run history \u0026 summary from WandB and produces per-run as well as\naggregated comparison artefacts.\n\"\"\"\nfrom __future__ import annotations\n\nimport argparse\nimport json\nfrom pathlib import Path\nfrom typing import Dict, List\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport wandb\nfrom omegaconf import OmegaConf\n\n\ndef _ensure_dir(path: Path) -\u003e None:\n    path.mkdir(parents=True, exist_ok=True)\n\n\ndef _export_json(obj, path: Path) -\u003e None:\n    with open(path, \"w\") as f:\n        json.dump(obj, f, indent=2)\n\n\ndef _plot_learning_curve(df: pd.DataFrame, metric: str, out_path: Path, title: str) -\u003e None:\n    sns.set(style=\"whitegrid\")\n    plt.figure(figsize=(6, 4))\n    sns.lineplot(x=df[\"_step\"], y=df[metric])\n    plt.title(title)\n    plt.xlabel(\"Training step\")\n    plt.ylabel(metric)\n    plt.tight_layout()\n    plt.savefig(out_path, format=\"pdf\")\n    plt.close()\n\n\ndef _plot_bar(values: Dict[str, float], ylabel: str, out_path: Path, title: str) -\u003e None:\n    sns.set(style=\"whitegrid\")\n    plt.figure(figsize=(8, 5))\n    ax = sns.barplot(x=list(values.keys()), y=list(values.values()))\n    for p in ax.patches:\n        _x = p.get_x() + p.get_width() / 2\n        _y = p.get_height()\n        ax.annotate(f\"{_y:.3f}\", (_x, _y), ha=\"center\", va=\"bottom\")\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plt.tight_layout()\n    plt.savefig(out_path, format=\"pdf\")\n    plt.close()\n\n\ndef main() -\u003e None:\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"results_dir\", type=str, help=\"Directory to store exported artefacts \u0026 figures\")\n    parser.add_argument(\"run_ids\", type=str, help=\"JSON-encoded list with WandB run IDs to analyse\")\n    args = parser.parse_args()\n\n    run_ids: List[str] = json.loads(args.run_ids)\n    results_root = Path(args.results_dir).expanduser().resolve()\n    _ensure_dir(results_root)\n\n    # -------- load global WandB credentials -----------------------------------\n    root_cfg = OmegaConf.load(\"config/config.yaml\")\n    entity, project = root_cfg.wandb.entity, root_cfg.wandb.project\n\n    api = wandb.Api()\n    aggregated: Dict[str, Dict[str, float]] = {}\n\n    # ------------------------- per-run processing ------------------------------\n    for rid in run_ids:\n        run = api.run(f\"{entity}/{project}/{rid}\")\n        history_df: pd.DataFrame = run.history()  # step-wise metrics\n        summary = dict(run.summary._json_dict)\n        cfg = dict(run.config)\n\n        run_dir = results_root / rid\n        _ensure_dir(run_dir)\n        _export_json(summary, run_dir / \"summary.json\")\n        _export_json(cfg, run_dir / \"config.json\")\n        history_df.to_json(run_dir / \"history.json\", orient=\"records\", indent=2)\n\n        # learning curves -------------------------------------------------------\n        if \"train_loss\" in history_df.columns:\n            _plot_learning_curve(history_df, \"train_loss\", run_dir / f\"{rid}_learning_curve.pdf\", title=f\"{rid} \u2013 training loss\")\n        if \"val_acc\" in history_df.columns:\n            _plot_learning_curve(history_df, \"val_acc\", run_dir / f\"{rid}_val_acc_curve.pdf\", title=f\"{rid} \u2013 validation accuracy\")\n\n        aggregated[rid] = {\n            \"best_val_acc\": summary.get(\"best_val_acc\", float(\"nan\")),\n            \"wall_clock_train_minutes\": summary.get(\"wall_clock_train_seconds\", float(\"nan\")) / 60.0,\n        }\n        print(f\"[Eval] Processed run {rid} \u2013 artefacts at {run_dir}\")\n\n    # ------------------------- aggregated comparison ---------------------------\n    cmp_dir = results_root / \"comparison\"\n    _ensure_dir(cmp_dir)\n    _export_json(aggregated, cmp_dir / \"aggregated_metrics.json\")\n\n    acc_vals = {k: v[\"best_val_acc\"] for k, v in aggregated.items()}\n    _plot_bar(acc_vals, ylabel=\"Best validation accuracy\", out_path=cmp_dir / \"comparison_best_val_acc.pdf\", title=\"Validation accuracy comparison\")\n\n    time_vals = {k: v[\"wall_clock_train_minutes\"] for k, v in aggregated.items()}\n    _plot_bar(time_vals, ylabel=\"Training time (min)\", out_path=cmp_dir / \"comparison_training_time.pdf\", title=\"Training time comparison\")\n\n    # print generated paths -----------------------------------------------------\n    for path in cmp_dir.rglob(\"*.pdf\"):\n        print(path)\n    for path in results_root.rglob(\"*.json\"):\n        print(path)\n\n\nif __name__ == \"__main__\":\n    main()", "main_py": "\"\"\"src/main.py\nMain orchestrator.  Applies mode-specific overrides and spawns ``src.train`` as\nsub-process.\n\"\"\"\nfrom __future__ import annotations\n\nimport subprocess\nimport sys\n\nimport hydra\nfrom omegaconf import DictConfig\n\n\n@hydra.main(config_path=\"../config\", config_name=\"config\")\ndef main(cfg: DictConfig) -\u003e None:\n    if \"run\" not in cfg or cfg.run is None:\n        print(\"[Main] You must provide run=\u003crun_id\u003e (file in config/run/)\")\n        sys.exit(1)\n\n    overrides = [\n        f\"run={cfg.run}\",\n        f\"results_dir={cfg.results_dir}\",\n        f\"mode={cfg.mode}\",\n    ]\n\n    if cfg.mode == \"trial\":\n        overrides += [\n            \"wandb.mode=disabled\",\n            \"training.epochs=1\",\n            \"optuna.n_trials=0\",\n            \"training.max_train_batches=2\",\n            \"training.max_val_batches=2\",\n        ]\n    elif cfg.mode == \"full\":\n        overrides += [\"wandb.mode=online\"]\n    else:\n        print(f\"[Main] Unknown mode \u0027{cfg.mode}\u0027 \u2013 expected \u0027trial\u0027 or \u0027full\u0027\")\n        sys.exit(1)\n\n    cmd = [\n        sys.executable,\n        \"-u\",\n        \"-m\",\n        \"src.train\",\n    ] + overrides\n\n    print(\"[Main] Executing:\", \" \".join(cmd))\n    subprocess.run(cmd, check=True)\n\n\nif __name__ == \"__main__\":\n    main()", "model_py": "\"\"\"src/model.py\nBuild baseline LoRA, AdaLoRA or the proposed GLoRA models.\n\"\"\"\nfrom __future__ import annotations\n\nfrom typing import Any\n\nimport torch\nfrom peft import AdaLoraConfig, LoraConfig, get_peft_model\nfrom transformers import AutoModelForSequenceClassification\n\nCACHE_DIR = \".cache/\"\n\n\nclass GLoRAWrapper:\n    \"\"\"Gradient-norm aware global rank re-allocation for LoRA.\"\"\"\n\n    def __init__(self, hf_model: torch.nn.Module, r_init: int, total_rank: int, beta: float, warmup_steps: int):\n        self.model = get_peft_model(hf_model, LoraConfig(r=r_init))\n        self.total_rank = int(total_rank)\n        self.beta = beta\n        self.warmup_steps = warmup_steps\n        self.step_idx = 0\n\n        self.lora_modules = [m for m in self.model.modules() if hasattr(m, \"lora_A\") and hasattr(m, \"lora_B\")]\n        self.g_ema = torch.zeros(len(self.lora_modules))\n        for idx, mod in enumerate(self.lora_modules):\n            mod.lora_B.register_hook(self._make_grad_hook(idx))\n\n    def _make_grad_hook(self, idx: int):\n        def _hook(grad):\n            gn = grad.norm().detach().cpu()\n            self.g_ema[idx] = self.beta * self.g_ema[idx] + (1 - self.beta) * gn\n            return grad\n        return _hook\n\n    # ----------------------------------------------------------------------\n    def step_callback(self):\n        self.step_idx += 1\n        if self.step_idx == self.warmup_steps:\n            self._reallocate()\n\n    def _reallocate(self):\n        scores = self.g_ema / self.g_ema.sum()\n        new_ranks = torch.round(scores * self.total_rank).int().tolist()\n        diff = self.total_rank - sum(new_ranks)\n        for i in range(abs(diff)):\n            new_ranks[i % len(new_ranks)] += 1 if diff \u003e 0 else -1\n\n        for new_r, module in zip(new_ranks, self.lora_modules):\n            old_r = module.lora_A.weight.size(0)\n            if new_r == old_r:\n                continue\n            keep = min(old_r, new_r)\n            with torch.no_grad():\n                A_old = module.lora_A.weight.data[:keep].clone()\n                B_old = module.lora_B.weight.data[:keep].clone()\n                module.update_layer(r=new_r)\n                module.lora_A.weight.data[:keep] = A_old\n                module.lora_B.weight.data[:keep] = B_old\n        print(\"[GLoRA] Re-allocated ranks \u2192\", new_ranks)\n\n\n# ------------------------------------------------------------------------------\n# Public builder ---------------------------------------------------------------\n# ------------------------------------------------------------------------------\n\ndef build_model(cfg: Any, num_labels: int):\n    base = AutoModelForSequenceClassification.from_pretrained(cfg.model.backbone, num_labels=num_labels, cache_dir=CACHE_DIR)\n\n    method = str(cfg.method_name).lower()\n    if method == \"glora\":\n        return GLoRAWrapper(\n            base,\n            r_init=cfg.model.peft.init_rank,\n            total_rank=cfg.glo_ra.total_rank_budget,\n            beta=float(cfg.glo_ra.beta_ema),\n            warmup_steps=int(cfg.glo_ra.warmup_steps),\n        )\n    elif method == \"adalora\":\n        ada_cfg = AdaLoraConfig(\n            r=cfg.model.peft.init_rank,\n            target_r=cfg.adalora.total_rank_budget,\n            lora_alpha=16,\n            beta1=cfg.adalora.beta1,\n            beta2=cfg.adalora.beta2,\n            orth_reg_weight=cfg.adalora.orth_reg_weight,\n            tinit=cfg.adalora.adaptation_start_step,\n        )\n        return get_peft_model(base, ada_cfg)\n    else:  # vanilla LoRA baseline\n        lora_cfg = LoraConfig(r=cfg.model.peft.init_rank, lora_alpha=16)\n        return get_peft_model(base, lora_cfg)", "preprocess_py": "\"\"\"src/preprocess.py\nDataset loading \u0026 tokenisation utilities (GLUE tasks).\n\"\"\"\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom typing import Dict, Tuple\n\nimport torch\nfrom datasets import load_dataset\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\n\nCACHE_DIR = \".cache/\"\n\n\ndef _get_glue_subset(full_name: str) -\u003e str:\n    assert full_name.startswith(\"glue_\"), \"Dataset name must start with \u0027glue_\u0027\"\n    return full_name.split(\"_\", 1)[1]\n\n\ndef _sentence_keys(task: str) -\u003e Tuple[str, str | None]:\n    mapping: Dict[str, Tuple[str, str | None]] = {\n        \"mnli\": (\"premise\", \"hypothesis\"),\n        \"sst2\": (\"sentence\", None),\n        \"rte\": (\"sentence1\", \"sentence2\"),\n    }\n    if task not in mapping:\n        raise ValueError(f\"Unsupported GLUE task {task}\")\n    return mapping[task]\n\n\n@dataclass\nclass GLUEDataModule:\n    cfg: any  # OmegaConf subtree\n    tokenizer: AutoTokenizer\n\n    def __post_init__(self):\n        task = _get_glue_subset(self.cfg.dataset.name)\n        raw = load_dataset(\"glue\", task, cache_dir=CACHE_DIR)\n        self.num_labels = raw[\"train\"].features[\"label\"].num_classes\n\n        k1, k2 = _sentence_keys(task)\n\n        def _tok(batch):\n            if k2 is None:\n                return self.tokenizer(batch[k1], truncation=True, max_length=self.cfg.dataset.max_length)\n            return self.tokenizer(batch[k1], batch[k2], truncation=True, max_length=self.cfg.dataset.max_length)\n\n        tokenised = raw.map(_tok, batched=True, remove_columns=raw[\"train\"].column_names)\n        collator = DataCollatorWithPadding(self.tokenizer)\n\n        self.train_loader = DataLoader(\n            tokenised[\"train\"],\n            shuffle=True,\n            batch_size=self.cfg.dataset.batch_size,\n            collate_fn=collator,\n            num_workers=4,\n        )\n\n        val_key = \"validation_matched\" if task == \"mnli\" else \"validation\"\n        self.val_loader = DataLoader(\n            tokenised[val_key],\n            shuffle=False,\n            batch_size=self.cfg.dataset.batch_size,\n            collate_fn=collator,\n            num_workers=4,\n        )", "pyproject_toml": "[project]\nname = \"glora_experiment\"\nversion = \"0.1.0\"\ndependencies = [\n    \"torch\u003e=2.0.0\",\n    \"transformers\u003e=4.37.0\",\n    \"datasets\u003e=2.14.0\",\n    \"peft\u003e=0.5.0\",\n    \"hydra-core\u003e=1.3.2\",\n    \"wandb\u003e=0.16.0\",\n    \"optuna\u003e=3.4.0\",\n    \"pandas\u003e=2.0.0\",\n    \"matplotlib\u003e=3.7.0\",\n    \"seaborn\u003e=0.13.0\",\n    \"scipy\u003e=1.11.0\",\n    \"tqdm\u003e=4.66.0\",\n]\n", "train_py": "\"\"\"src/train.py\nSingle-run training executor with Hydra, Optuna and comprehensive WandB logging.\nFixes over previous version:\n    \u2022 WandB is *not* initialised while Optuna is searching \u2013 only the final\n      training run (best hyper-parameters) is logged.\n    \u2022 Trial-mode now also limits *validation* batches so the dry-run finishes\n      very quickly.\n\"\"\"\nfrom __future__ import annotations\n\nimport math\nimport time\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional\n\nimport hydra\nimport optuna\nimport torch\nimport wandb\nfrom omegaconf import DictConfig, OmegaConf\nfrom optuna.trial import Trial\nfrom torch.nn.utils import clip_grad_norm_\nfrom torch.optim import AdamW\nfrom transformers import AutoTokenizer, get_linear_schedule_with_warmup\n\nfrom src.model import GLoRAWrapper, build_model\nfrom src.preprocess import GLUEDataModule\n\nCACHE_DIR = \".cache/\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ------------------------------------------------------------------------------\n# Helper utilities --------------------------------------------------------------\n# ------------------------------------------------------------------------------\n\ndef _apply_optuna_params(cfg: DictConfig, params: Dict[str, Any]) -\u003e DictConfig:\n    \"\"\"Return *copy* of ``cfg`` with ``params`` written into the tree (dot-keys).\"\"\"\n    cfg = OmegaConf.create(OmegaConf.to_container(cfg, resolve=True))\n    for key, value in params.items():\n        node = cfg\n        parts = key.split(\".\")\n        for p in parts[:-1]:\n            if p not in node or node[p] is None:\n                node[p] = {}\n            node = node[p]\n        node[parts[-1]] = value\n    return cfg\n\n\ndef _accuracy(preds: torch.Tensor, labels: torch.Tensor) -\u003e float:\n    return (preds == labels).float().mean().item()\n\n\n# ------------------------------------------------------------------------------\n# Core training routine ---------------------------------------------------------\n# ------------------------------------------------------------------------------\n\ndef _train_one_run(cfg: DictConfig, trial: Optional[Trial] = None) -\u003e float:\n    \"\"\"Train for *one* hyper-parameter configuration.\n\n    If ``trial`` is given the function is inside an Optuna optimisation loop.\n    In that case **WandB logging is suppressed** \u2013 only the *final* best run\n    (trial is ``None``) is logged to WandB, satisfying the specification.\n    \"\"\"\n\n    # ------------------------------ apply Optuna suggestions -------------------\n    if trial is not None and cfg.optuna.search_space:\n        sampled: Dict[str, Any] = {}\n        for name, space in cfg.optuna.search_space.items():\n            stype: str = space.type\n            if stype == \"loguniform\":\n                sampled[name] = trial.suggest_float(name, space.low, space.high, log=True)\n            elif stype == \"uniform\":\n                sampled[name] = trial.suggest_float(name, space.low, space.high)\n            elif stype == \"int\":\n                sampled[name] = trial.suggest_int(name, space.low, space.high)\n            elif stype == \"categorical\":\n                sampled[name] = trial.suggest_categorical(name, space.choices)\n            else:\n                raise ValueError(f\"Unsupported search-space type \u0027{stype}\u0027 for key {name}\")\n        cfg = _apply_optuna_params(cfg, sampled)\n\n    # ------------------------------ WandB initialisation ------------------------\n    wandb_run: Optional[wandb.wandb_sdk.wandb_run.Run] = None\n    wandb_enabled = (trial is None) and (cfg.wandb.mode != \"disabled\")\n    if wandb_enabled:\n        wandb_run = wandb.init(\n            entity=cfg.wandb.entity,\n            project=cfg.wandb.project,\n            id=cfg.run.run_id,\n            config=OmegaConf.to_container(cfg, resolve=True),\n            resume=\"allow\",\n            mode=cfg.wandb.mode,\n        )\n        print(f\"[WandB] Run URL: {wandb_run.url}\")\n\n    # ------------------------------ Data loading --------------------------------\n    tokenizer = AutoTokenizer.from_pretrained(cfg.model.backbone, cache_dir=CACHE_DIR)\n    dm = GLUEDataModule(cfg, tokenizer)\n    train_loader, val_loader, num_labels = dm.train_loader, dm.val_loader, dm.num_labels\n\n    # ------------------------------ Model construction --------------------------\n    module_or_wrapper = build_model(cfg, num_labels=num_labels)\n    if isinstance(module_or_wrapper, GLoRAWrapper):\n        model = module_or_wrapper.model\n        glora: Optional[GLoRAWrapper] = module_or_wrapper\n    else:\n        model = module_or_wrapper\n        glora = None\n    model.to(DEVICE)\n\n    # ------------------------------ Optimiser \u0026 LR sched ------------------------\n    no_decay = [\"bias\", \"LayerNorm.weight\"]\n    param_groups = [\n        {\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n         \"weight_decay\": cfg.training.weight_decay},\n        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n         \"weight_decay\": 0.0},\n    ]\n    optim = AdamW(param_groups, lr=cfg.training.learning_rate)\n\n    updates_per_epoch = math.ceil(len(train_loader) / cfg.training.gradient_accumulation_steps)\n    total_updates = updates_per_epoch * cfg.training.epochs\n    scheduler = get_linear_schedule_with_warmup(\n        optim,\n        num_warmup_steps=cfg.training.lr_warmup_steps,\n        num_training_steps=total_updates,\n    )\n\n    # ------------------------------ Training loop ------------------------------\n    best_val_acc = -1.0\n    global_step = 0\n    start_time = time.time()\n\n    for epoch in range(cfg.training.epochs):\n        model.train()\n        epoch_loss = 0.0\n        correct, seen = 0, 0\n\n        for step, batch in enumerate(train_loader):\n            if cfg.training.max_train_batches is not None and step \u003e= cfg.training.max_train_batches:\n                break\n            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n            out = model(**batch)\n            loss = out.loss / cfg.training.gradient_accumulation_steps\n            loss.backward()\n            epoch_loss += loss.item()\n\n            # accuracy (per-batch)\n            if \"labels\" in batch:\n                preds = torch.argmax(out.logits.detach(), dim=-1)\n                correct += (preds == batch[\"labels\"]).sum().item()\n                seen += preds.size(0)\n\n            if (step + 1) % cfg.training.gradient_accumulation_steps == 0:\n                clip_grad_norm_(model.parameters(), cfg.training.max_grad_norm)\n                optim.step()\n                scheduler.step()\n                optim.zero_grad()\n                global_step += 1\n\n                if glora is not None:\n                    glora.step_callback()\n\n                if wandb_run is not None:\n                    wandb.log({\n                        \"train_loss\": loss.item() * cfg.training.gradient_accumulation_steps,\n                        \"train_lr\": scheduler.get_last_lr()[0],\n                        \"train_acc\": (correct / seen) if seen else 0.0,\n                        \"epoch\": epoch,\n                    }, step=global_step)\n\n        # ------------------------- Validation -----------------------------------\n        model.eval()\n        val_correct, val_total, val_loss = 0, 0, 0.0\n        with torch.no_grad():\n            for vstep, batch in enumerate(val_loader):\n                if cfg.training.max_val_batches is not None and vstep \u003e= cfg.training.max_val_batches:\n                    break\n                batch = {k: v.to(DEVICE) for k, v in batch.items()}\n                out = model(**batch)\n                val_loss += out.loss.item()\n                preds = torch.argmax(out.logits, dim=-1)\n                val_correct += (preds == batch[\"labels\"]).sum().item()\n                val_total += preds.size(0)\n        val_acc = val_correct / val_total if val_total else 0.0\n\n        if wandb_run is not None:\n            wandb.log({\n                \"val_loss\": val_loss / max(1, (vstep + 1)),\n                \"val_acc\": val_acc,\n                \"epoch\": epoch,\n            }, step=global_step)\n\n        # ------------------------- Save best model ------------------------------\n        if val_acc \u003e best_val_acc:\n            best_val_acc = val_acc\n            ckpt_dir = Path(cfg.results_dir) / cfg.run.run_id\n            ckpt_dir.mkdir(parents=True, exist_ok=True)\n            torch.save(model.state_dict(), ckpt_dir / \"best_model.pt\")\n\n    wall_clock = time.time() - start_time\n\n    # ------------------------------ WandB summary ------------------------------\n    if wandb_run is not None:\n        wandb_run.summary[\"best_val_acc\"] = best_val_acc\n        wandb_run.summary[\"wall_clock_train_seconds\"] = wall_clock\n        wandb_run.finish()\n\n    return best_val_acc\n\n\n# ------------------------------------------------------------------------------\n# Hydra main entry --------------------------------------------------------------\n# ------------------------------------------------------------------------------\n\n@hydra.main(config_path=\"../config\", config_name=\"config\")\ndef _hydra_main(cfg: DictConfig) -\u003e None:\n    \"\"\"Entrypoint invoked by ``python -m src.train``.\n\n    Runs Optuna hyper-parameter optimisation (if requested) *without* WandB\n    logging for intermediate trials, then trains once more with the best params\n    and logs that final run.\n    \"\"\"\n\n    if cfg.optuna.n_trials and cfg.optuna.n_trials \u003e 0:\n        study = optuna.create_study(direction=cfg.optuna.direction)\n\n        def objective(trial: Trial):\n            cfg_trial = OmegaConf.create(OmegaConf.to_container(cfg, resolve=True))  # deep-copy\n            return _train_one_run(cfg_trial, trial)\n\n        study.optimize(objective, n_trials=cfg.optuna.n_trials)\n        print(\"[Optuna] Best trial params:\", study.best_trial.params)\n\n        best_cfg = _apply_optuna_params(cfg, study.best_trial.params)\n        best_metric = _train_one_run(best_cfg, trial=None)  # FINAL run \u2192 WandB\n    else:\n        best_metric = _train_one_run(cfg, trial=None)\n\n    print(f\"[Train] Run {cfg.run.run_id} finished \u2013 best val acc = {best_metric:.4f}\")\n\n\nif __name__ == \"__main__\":\n    _hydra_main()"}

Analyze the experiment code thoroughly. Ensure it is complete, executable, and ready for publication-quality research experiments.
Output:
{
    "is_code_ready": false,
    "code_issue": "Data preprocessing drops the supervision column. In src/preprocess.py `raw.map(..., remove_columns=raw[\"train\"].column_names)` removes *all* original columns, including \"label\". The resulting batches therefore contain no `labels` key, so src/train.py fails when it tries to access `batch[\"labels\"]` and when the HF model expects a `labels` tensor. Remove the `label` column from `remove_columns` (or simply omit the argument) so that the mapped dataset keeps its targets. Until this is fixed the experiment cannot run."
}
