run_id: comparative-1-DeBERTa-v3-base-86M--GLUE-MNLI
method: comparative-1
method_name: AdaLoRA
model:
  backbone: microsoft/deberta-v3-base
  peft:
    type: adalora
    init_rank: 8
  hidden_size: 768
  num_layers: 12
  num_parameters: 86M
dataset:
  name: glue_mnli
  max_length: 256
  batch_size: 32
training:
  epochs: 3
  optimizer: adamw
  learning_rate: 2e-4
  weight_decay: 0.01
  lr_scheduler: linear
  lr_warmup_steps: 1000
  max_grad_norm: 1.0
  gradient_checkpointing: false
adalora:
  total_rank_budget: 128
  init_rank: 8
  beta1: 0.9
  beta2: 0.99
  orth_reg_weight: 5.0e-4
  adaptation_start_step: 12000
evaluation:
  metrics: [accuracy, matthews_corrcoef]
  track_training_time: true
hardware:
  gpu_type: a100
  num_gpus: 1
optuna:
  n_trials: 25
  direction: maximize
  metric: validation_accuracy
  search_space:
    learning_rate:
      type: loguniform
      low: 1.0e-4
      high: 5.0e-4
    orth_reg_weight:
      type: loguniform
      low: 1.0e-5
      high: 1.0e-3
    adaptation_start_step:
      type: int
      low: 500
      high: 1500
    total_rank_budget:
      type: categorical
      choices: [96, 128, 160]
    batch_size:
      type: categorical
      choices: [16, 32, 64]
